{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No logging configuration file found at: logging.yaml. Setting logging level to INFO.\n",
      "INFO:training:Initializing resources...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import comet_ml\n",
    "import sys\n",
    "sys.path.append(\"../modules\")\n",
    "\n",
    "from pathlib import Path\n",
    "from training.api import ChatAPI, FinQATrainingAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training.api.FinQATrainingAPI:Loading FinQA datasets from self._root_dataset_dir=PosixPath('../dataset')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6251/6251 [00:00<00:00, 9298.48 examples/s]\n",
      "Map: 100%|██████████| 1147/1147 [00:00<00:00, 9076.76 examples/s]\n",
      "INFO:training.api.FinQATrainingAPI:Debug mode enabled. Truncating datasets...\n",
      "INFO:training.api.FinQATrainingAPI:Loading model using self._model_id='tiiuae/falcon-7b-instruct'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "GPU 0 memory available: 12032 MiB\n",
      "GPU 1 memory available: 7854 MiB\n",
      "Available RAM: 59.13960266113281 GB\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.21s/it]\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/iusztinpaul/general/7e6e62e260da48ac894c30b9e2a411be\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_api = FinQATrainingAPI(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/iusztinpaul/general/7e6e62e260da48ac894c30b9e2a411be\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (82.62 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/iusztinpaul/huggingface/6109909b990e4803a5e779ce0a8e7421\n",
      "\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 01:26, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.169600</td>\n",
       "      <td>2.161313</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.160300</td>\n",
       "      <td>2.158114</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.000900</td>\n",
       "      <td>2.153488</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "INFO:accelerate.accelerator:The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/iusztinpaul/huggingface/6109909b990e4803a5e779ce0a8e7421\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [7]                   : (0.33, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_loss [3]               : (2.1534879207611084, 2.1613125801086426)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_perplexity [3]         : (6.771323768361981e-08, 6.858071088799989e-08)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_runtime [3]            : (6.9539, 6.9847)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_samples_per_second [3] : (0.859, 0.863)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps_per_second [3]   : (0.859, 0.863)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate               : 0.0002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [4]                    : (0.5245167016983032, 2.1696)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_flos                  : 245672765816832.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss                  : 2.110252062479655\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_runtime               : 63.9484\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_samples_per_second    : 0.188\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_steps_per_second      : 0.047\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_n_gpu                                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_no_sync_in_gradient_accumulation          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_setup_devices                             : cuda:0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adafactor                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta1                                 : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta2                                 : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_epsilon                               : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/auto_find_batch_size                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16_full_eval                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/data_seed                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_drop_last                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_num_workers                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_pin_memory                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_broadcast_buffers                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_bucket_cap_mb                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_find_unused_parameters                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout                                : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout_delta                          : 0:30:00\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/debug                                      : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed_plugin                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/default_optim                              : adamw_hf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/device                                     : cuda:0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/disable_tqdm                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/distributed_state                          : Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_eval                                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_predict                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_train                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_accumulation_steps                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_batch_size                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_delay                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_steps                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/evaluation_strategy                        : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_backend                               : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_full_eval                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_opt_level                             : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/framework                                  : pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp                                       : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_config                                : {'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_min_num_params                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_transformer_layer_cls_to_wrap         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/full_determinism                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_accumulation_steps                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/greater_is_better                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/group_by_length                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/half_precision_backend                     : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_model_id                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_private_repo                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_strategy                               : HubStrategy.EVERY_SAVE\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_token                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ignore_data_skip                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_inputs_for_metrics                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/jit_mode_eval                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_names                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_smoothing_factor                     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/learning_rate                              : 0.0002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/length_column_name                         : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/load_best_model_at_end                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_process_index                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_rank                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level                                  : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level_replica                          : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_on_each_node                           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_dir                                : ../logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_first_step                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_nan_inf_filter                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_steps                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_strategy                           : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_type                          : SchedulerType.CONSTANT\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_grad_norm                              : 0.3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_steps                                  : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/metric_for_best_model                      : loss\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/mp_parameters                              : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/n_gpu                                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/no_cuda                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/num_train_epochs                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim                                      : OptimizerNames.PAGED_ADAMW\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_args                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/output_dir                                 : ../results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/overwrite_output_dir                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/parallel_mode                              : ParallelMode.NOT_PARALLEL\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/past_index                                 : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_eval_batch_size                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_train_batch_size                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_eval_batch_size                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_train_batch_size                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/place_model_on_device                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/prediction_loss_only                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/process_index                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_model_id                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_organization                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_token                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ray_scope                                  : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/remove_unused_columns                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/report_to                                  : ['comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/resume_from_checkpoint                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/run_name                                   : ../results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_on_each_node                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_safetensors                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_steps                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_strategy                              : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_total_limit                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/seed                                       : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/sharded_ddp                                : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_log                                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_save                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/skip_memory_metrics                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tf32                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_backend                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_mode                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torchdynamo                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_metrics_debug                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_num_cores                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/train_batch_size                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_ipex                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_legacy_prediction_loop                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_mps_device                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_ratio                               : 0.03\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_steps                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/weight_decay                               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/world_size                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/xpu_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_auto_class                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_commit_hash                             : eb410fb6ffa9028e97adb801f0d6ec46d02f8b07\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_name_or_path                            : tiiuae/falcon-7b-instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/add_cross_attention                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/alibi                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/apply_residual_connection_post_layernorm : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/architectures                            : ['RWForCausalLM']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attention_dropout                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attribute_map                            : {'num_hidden_layers': 'n_layer', 'num_attention_heads': 'n_head'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/auto_map                                 : {'AutoConfig': 'tiiuae/falcon-7b-instruct--configuration_RW.RWConfig', 'AutoModelForCausalLM': 'tiiuae/falcon-7b-instruct--modelling_RW.RWForCausalLM'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bad_words_ids                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/begin_suppress_tokens                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bias                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bos_token_id                             : 11\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/chunk_size_feed_forward                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/cross_attention_hidden_size              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder_start_token_id                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/diversity_penalty                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/do_sample                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/early_stopping                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder_no_repeat_ngram_size             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/eos_token_id                             : 11\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/exponential_decay_length_penalty         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/finetuning_task                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_bos_token_id                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_eos_token_id                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/head_dim                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/hidden_dropout                           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/hidden_size                              : 4544\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/id2label                                 : {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/initializer_range                        : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_composition                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_decoder                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_encoder_decoder                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/keys_to_ignore_at_inference              : ['past_key_values']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/label2id                                 : {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/layer_norm_epsilon                       : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/length_penalty                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/max_length                               : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/min_length                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/model_type                               : RefinedWebModel\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/multi_query                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_head                                   : 71\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_layer                                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/name_or_path                             : tiiuae/falcon-7b-instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/no_repeat_ngram_size                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beam_groups                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beams                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_labels                               : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_return_sequences                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_attentions                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_hidden_states                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_scores                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pad_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/parallel_attn                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/prefix                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/problem_type                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pruned_heads                             : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/quantization_config                      : BitsAndBytesConfig {\n",
      "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"load_in_4bit\": true\n",
      "}\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/remove_invalid_values                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/repetition_penalty                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict_in_generate                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/rotary                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/sep_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/suppress_tokens                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/task_specific_params                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/temperature                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tf_legacy_loss                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_encoder_decoder                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_word_embeddings                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tokenizer_class                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_k                                    : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_p                                    : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torch_dtype                              : torch.bfloat16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torchscript                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/transformers_version                     : 4.27.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/typical_p                                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_bfloat16                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_cache                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_return_dict                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/vocab_size                               : 65024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                    : 33 (656.07 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (47.87 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[36m─────────────────────────────────────────────── \u001b[0m\u001b[1;36mNew Comet feature!\u001b[0m\u001b[36m ───────────────────────────────────────────────\u001b[0m\n",
      "Log your models to better track, deploy, share, and reproduce your work using: 'comet_ml.integration.pytorch.log_model'.\n",
      "Learn more at: https://comet.com/docs/v2/pytorch_log_model\n",
      "\n",
      "Hide this message by setting environment variable \"COMET_DISABLE_ANNOUNCEMENT=1\" \n",
      "\u001b[36m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 6 file(s), remaining 462.31 MB/656.09 MB\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 32.10 MB/656.09 MB, Throughput 28.65 MB/s, ETA ~2s\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 1 asset(s), remaining 5.18 MB/656.09 MB, Throughput 1.79 MB/s, ETA ~3s\n",
      "INFO:training.api.FinQATrainingAPI:Logging best model from ../results/checkpoint-3 to the model registry...\n",
      "INFO:training.api.FinQATrainingAPI:Best model checkpoint has 11 files\n"
     ]
    }
   ],
   "source": [
    "trainer = training_api.train()\n",
    "\n",
    " # When we ran the training in a Jupyter Notebook, we have to manually end the Comet ML experiment.\n",
    "experiment = comet_ml.get_global_experiment()\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 2.1696, 'learning_rate': 0.0002, 'epoch': 0.33, 'step': 1},\n",
       " {'eval_loss': 2.161283254623413,\n",
       "  'eval_perplexity': 6.858097378881212e-08,\n",
       "  'eval_runtime': 6.9463,\n",
       "  'eval_samples_per_second': 0.864,\n",
       "  'eval_steps_per_second': 0.864,\n",
       "  'epoch': 0.33,\n",
       "  'step': 1},\n",
       " {'loss': 2.1604, 'learning_rate': 0.0002, 'epoch': 0.67, 'step': 2},\n",
       " {'eval_loss': 2.1581273078918457,\n",
       "  'eval_perplexity': 6.82205012481063e-08,\n",
       "  'eval_runtime': 6.9761,\n",
       "  'eval_samples_per_second': 0.86,\n",
       "  'eval_steps_per_second': 0.86,\n",
       "  'epoch': 0.67,\n",
       "  'step': 2},\n",
       " {'loss': 2.0008, 'learning_rate': 0.0002, 'epoch': 1.0, 'step': 3},\n",
       " {'eval_loss': 2.1535491943359375,\n",
       "  'eval_perplexity': 6.768559757119874e-08,\n",
       "  'eval_runtime': 6.9658,\n",
       "  'eval_samples_per_second': 0.861,\n",
       "  'eval_steps_per_second': 0.861,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3},\n",
       " {'train_runtime': 63.6673,\n",
       "  'train_samples_per_second': 0.188,\n",
       "  'train_steps_per_second': 0.047,\n",
       "  'total_flos': 245672765816832.0,\n",
       "  'train_loss': 2.110257387161255,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = finqa.FinQADataset(\n",
    "#     data_path=ROOT_DATASET_DIR / \"private_test.json\", scope=constants.Scope.TESTING\n",
    "# ).to_huggingface()\n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_api = ChatAPI(peft_model_id=Path(\"..\") / \"results\" / \"checkpoint-280\", max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     chat_api.ask(\n",
    "#         question=test_dataset[\"text\"][0],\n",
    "#     )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
