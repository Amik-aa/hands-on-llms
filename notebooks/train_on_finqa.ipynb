{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import comet_ml\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../modules\")\n",
    "\n",
    "from pathlib import Path\n",
    "from training.api import ChatAPI, FinQATrainingAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:training.api.FinQATrainingAPI:Loading FinQA datasets from self._root_dataset_dir=PosixPath('/workspace/dataset/dataset')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/workspace/dataset/dataset/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m training_api \u001b[39m=\u001b[39m FinQATrainingAPI(debug\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/notebooks/../modules/training/api/FinQATrainingAPI.py:41\u001b[0m, in \u001b[0;36mFinQATrainingAPI.__init__\u001b[0;34m(self, root_dataset_dir, model_id, training_arguments, max_seq_length, debug)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_seq_length \u001b[39m=\u001b[39m max_seq_length\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debug \u001b[39m=\u001b[39m debug\n\u001b[0;32m---> 41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_training_dataset, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validation_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_data()\n\u001b[1;32m     42\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_peft_config \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_model()\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/notebooks/../modules/training/api/FinQATrainingAPI.py:50\u001b[0m, in \u001b[0;36mFinQATrainingAPI.load_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Dataset, Dataset]:\n\u001b[1;32m     49\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading FinQA datasets from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_root_dataset_dir\u001b[39m=}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m     training_dataset \u001b[39m=\u001b[39m finqa\u001b[39m.\u001b[39;49mFinQADataset(\n\u001b[1;32m     51\u001b[0m         data_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_root_dataset_dir \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtrain.json\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     52\u001b[0m         scope\u001b[39m=\u001b[39;49mconstants\u001b[39m.\u001b[39;49mScope\u001b[39m.\u001b[39;49mTRAINING,\n\u001b[1;32m     53\u001b[0m     )\u001b[39m.\u001b[39mto_huggingface()\n\u001b[1;32m     54\u001b[0m     validation_dataset \u001b[39m=\u001b[39m finqa\u001b[39m.\u001b[39mFinQADataset(\n\u001b[1;32m     55\u001b[0m         data_path\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_root_dataset_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest.json\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     56\u001b[0m         scope\u001b[39m=\u001b[39mconstants\u001b[39m.\u001b[39mScope\u001b[39m.\u001b[39mTRAINING,\n\u001b[1;32m     57\u001b[0m     )\u001b[39m.\u001b[39mto_huggingface()\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debug \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/notebooks/../modules/training/data/finqa.py:41\u001b[0m, in \u001b[0;36mFinQADataset.__init__\u001b[0;34m(self, data_path, scope)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_path \u001b[39m=\u001b[39m data_path\n\u001b[1;32m     39\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scope \u001b[39m=\u001b[39m scope\n\u001b[0;32m---> 41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload(data_path)\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/notebooks/../modules/training/data/finqa.py:44\u001b[0m, in \u001b[0;36mFinQADataset.load\u001b[0;34m(self, data_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\u001b[39mself\u001b[39m, data_path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[FinQASample]:\n\u001b[0;32m---> 44\u001b[0m     data \u001b[39m=\u001b[39m load_json(data_path)\n\u001b[1;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeserialize(data)\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/notebooks/../modules/training/data/utils.py:6\u001b[0m, in \u001b[0;36mload_json\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_json\u001b[39m(path: Path) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[39mwith\u001b[39;00m path\u001b[39m.\u001b[39;49mopen(\u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      9\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3.10/pathlib.py:1119\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1118\u001b[0m     encoding \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_accessor\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m, mode, buffering, encoding, errors,\n\u001b[1;32m   1120\u001b[0m                            newline)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/workspace/dataset/dataset/train.json'"
     ]
    }
   ],
   "source": [
    "training_api = FinQATrainingAPI(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_api._training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:18:53,260 - INFO - Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/iusztinpaul/hands-on-llms/53b88214ae2449faa77d470bcb8362a5\n",
      "\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 01:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.169600</td>\n",
       "      <td>2.161291</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>2.158099</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.000800</td>\n",
       "      <td>2.153468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:19:14,406 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:14,472 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:14,473 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:15,464 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:15,530 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:15,531 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:16,524 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:16,590 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:16,591 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:17,585 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:17,651 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:17,652 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:18,649 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:18,715 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:18,716 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:33,952 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:34,018 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:34,019 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:35,013 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:35,079 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:35,080 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:36,076 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:36,143 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:36,143 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:37,142 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:37,208 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:37,209 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:38,210 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:38,276 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:38,277 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:53,432 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:53,498 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:53,499 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:54,495 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:54,562 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:54,563 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:55,560 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:55,627 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:55,627 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:56,625 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:56,692 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:56,692 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:57,694 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:57,760 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:57,761 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/iusztinpaul/hands-on-llms/53b88214ae2449faa77d470bcb8362a5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [7]                   : (0.33, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_loss [3]               : (2.153467893600464, 2.1612908840179443)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_perplexity [3]         : (6.771504246216864e-08, 6.859195877950697e-08)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_runtime [3]            : (6.9485, 6.9809)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_samples_per_second [3] : (0.859, 0.863)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps_per_second [3]   : (0.859, 0.863)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate               : 0.0002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [4]                    : (0.5245167016983032, 2.1696)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_flos                  : 245672765816832.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss                  : 2.110236565272013\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_runtime               : 63.7355\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_samples_per_second    : 0.188\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_steps_per_second      : 0.047\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_n_gpu                                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_no_sync_in_gradient_accumulation          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_setup_devices                             : cuda:0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adafactor                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta1                                 : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta2                                 : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_epsilon                               : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/auto_find_batch_size                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16_full_eval                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/data_seed                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_drop_last                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_num_workers                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_pin_memory                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_broadcast_buffers                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_bucket_cap_mb                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_find_unused_parameters                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout                                : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout_delta                          : 0:30:00\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/debug                                      : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed_plugin                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/default_optim                              : adamw_hf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/device                                     : cuda:0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/disable_tqdm                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/distributed_state                          : Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_eval                                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_predict                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_train                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_accumulation_steps                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_batch_size                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_delay                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_steps                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/evaluation_strategy                        : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_backend                               : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_full_eval                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_opt_level                             : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/framework                                  : pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp                                       : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_config                                : {'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_min_num_params                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_transformer_layer_cls_to_wrap         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/full_determinism                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_accumulation_steps                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/greater_is_better                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/group_by_length                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/half_precision_backend                     : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_model_id                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_private_repo                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_strategy                               : HubStrategy.EVERY_SAVE\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_token                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ignore_data_skip                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_inputs_for_metrics                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/jit_mode_eval                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_names                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_smoothing_factor                     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/learning_rate                              : 0.0002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/length_column_name                         : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/load_best_model_at_end                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_process_index                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_rank                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level                                  : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level_replica                          : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_on_each_node                           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_dir                                : ../../logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_first_step                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_nan_inf_filter                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_steps                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_strategy                           : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_type                          : SchedulerType.CONSTANT\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_grad_norm                              : 0.3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_steps                                  : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/metric_for_best_model                      : loss\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/mp_parameters                              : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/n_gpu                                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/no_cuda                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/num_train_epochs                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim                                      : OptimizerNames.PAGED_ADAMW\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_args                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/output_dir                                 : ../../results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/overwrite_output_dir                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/parallel_mode                              : ParallelMode.NOT_PARALLEL\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/past_index                                 : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_eval_batch_size                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_train_batch_size                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_eval_batch_size                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_train_batch_size                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/place_model_on_device                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/prediction_loss_only                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/process_index                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_model_id                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_organization                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_token                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ray_scope                                  : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/remove_unused_columns                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/report_to                                  : ['comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/resume_from_checkpoint                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/run_name                                   : ../../results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_on_each_node                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_safetensors                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_steps                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_strategy                              : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_total_limit                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/seed                                       : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/sharded_ddp                                : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_log                                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_save                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/skip_memory_metrics                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tf32                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_backend                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_mode                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torchdynamo                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_metrics_debug                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_num_cores                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/train_batch_size                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_ipex                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_legacy_prediction_loop                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_mps_device                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_ratio                               : 0.03\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_steps                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/weight_decay                               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/world_size                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/xpu_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_auto_class                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_commit_hash                             : eb410fb6ffa9028e97adb801f0d6ec46d02f8b07\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_name_or_path                            : tiiuae/falcon-7b-instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/add_cross_attention                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/alibi                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/apply_residual_connection_post_layernorm : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/architectures                            : ['RWForCausalLM']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attention_dropout                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attribute_map                            : {'num_hidden_layers': 'n_layer', 'num_attention_heads': 'n_head'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/auto_map                                 : {'AutoConfig': 'tiiuae/falcon-7b-instruct--configuration_RW.RWConfig', 'AutoModelForCausalLM': 'tiiuae/falcon-7b-instruct--modelling_RW.RWForCausalLM'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bad_words_ids                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/begin_suppress_tokens                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bias                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bos_token_id                             : 11\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/chunk_size_feed_forward                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/cross_attention_hidden_size              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder_start_token_id                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/diversity_penalty                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/do_sample                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/early_stopping                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder_no_repeat_ngram_size             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/eos_token_id                             : 11\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/exponential_decay_length_penalty         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/finetuning_task                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_bos_token_id                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_eos_token_id                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/head_dim                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/hidden_dropout                           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/hidden_size                              : 4544\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/id2label                                 : {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/initializer_range                        : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_composition                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_decoder                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_encoder_decoder                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/keys_to_ignore_at_inference              : ['past_key_values']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/label2id                                 : {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/layer_norm_epsilon                       : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/length_penalty                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/max_length                               : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/min_length                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/model_type                               : RefinedWebModel\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/multi_query                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_head                                   : 71\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_layer                                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/name_or_path                             : tiiuae/falcon-7b-instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/no_repeat_ngram_size                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beam_groups                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beams                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_labels                               : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_return_sequences                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_attentions                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_hidden_states                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_scores                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pad_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/parallel_attn                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/prefix                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/problem_type                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pruned_heads                             : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/quantization_config                      : BitsAndBytesConfig {\n",
      "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"load_in_4bit\": true\n",
      "}\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/remove_invalid_values                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/repetition_penalty                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict_in_generate                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/rotary                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/sep_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/suppress_tokens                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/task_specific_params                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/temperature                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tf_legacy_loss                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_encoder_decoder                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_word_embeddings                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tokenizer_class                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_k                                    : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_p                                    : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torch_dtype                              : torch.bfloat16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torchscript                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/transformers_version                     : 4.27.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/typical_p                                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_bfloat16                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_cache                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_return_dict                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/vocab_size                               : 65024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                    : 33 (656.08 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (369.28 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[36m─────────────────────────────────────────────── \u001b[0m\u001b[1;36mNew Comet feature!\u001b[0m\u001b[36m ───────────────────────────────────────────────\u001b[0m\n",
      "Log your models to better track, deploy, share, and reproduce your work using: 'comet_ml.integration.pytorch.log_model'.\n",
      "Learn more at: https://comet.com/docs/v2/pytorch_log_model\n",
      "\n",
      "Hide this message by setting environment variable \"COMET_DISABLE_ANNOUNCEMENT=1\" \n",
      "\u001b[36m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 6 file(s), remaining 460.23 MB/656.14 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:20:15,934 - INFO - Logging best model from ../../results/checkpoint-3 to the model registry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/iusztinpaul/hands-on-llms/bcc002e365064a97bbee6d5cf324cba3\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/iusztinpaul/hands-on-llms/bcc002e365064a97bbee6d5cf324cba3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (369.28 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element            : 11 (218.69 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 file(s), remaining 146.84 MB/218.75 MB\n"
     ]
    }
   ],
   "source": [
    "trainer = training_api.train()\n",
    "\n",
    " # When we ran the training in a Jupyter Notebook, we have to manually end the Comet ML experiment.\n",
    "experiment = comet_ml.get_global_experiment()\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 2.1696, 'learning_rate': 0.0002, 'epoch': 0.33, 'step': 1},\n",
       " {'eval_loss': 2.161283254623413,\n",
       "  'eval_perplexity': 6.858097378881212e-08,\n",
       "  'eval_runtime': 6.9463,\n",
       "  'eval_samples_per_second': 0.864,\n",
       "  'eval_steps_per_second': 0.864,\n",
       "  'epoch': 0.33,\n",
       "  'step': 1},\n",
       " {'loss': 2.1604, 'learning_rate': 0.0002, 'epoch': 0.67, 'step': 2},\n",
       " {'eval_loss': 2.1581273078918457,\n",
       "  'eval_perplexity': 6.82205012481063e-08,\n",
       "  'eval_runtime': 6.9761,\n",
       "  'eval_samples_per_second': 0.86,\n",
       "  'eval_steps_per_second': 0.86,\n",
       "  'epoch': 0.67,\n",
       "  'step': 2},\n",
       " {'loss': 2.0008, 'learning_rate': 0.0002, 'epoch': 1.0, 'step': 3},\n",
       " {'eval_loss': 2.1535491943359375,\n",
       "  'eval_perplexity': 6.768559757119874e-08,\n",
       "  'eval_runtime': 6.9658,\n",
       "  'eval_samples_per_second': 0.861,\n",
       "  'eval_steps_per_second': 0.861,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3},\n",
       " {'train_runtime': 63.6673,\n",
       "  'train_samples_per_second': 0.188,\n",
       "  'train_steps_per_second': 0.047,\n",
       "  'total_flos': 245672765816832.0,\n",
       "  'train_loss': 2.110257387161255,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = finqa.FinQADataset(\n",
    "#     data_path=ROOT_DATASET_DIR / \"private_test.json\", scope=constants.Scope.TESTING\n",
    "# ).to_huggingface()\n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_api = ChatAPI(peft_model_id=Path(\"..\") / \"results\" / \"checkpoint-280\", max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     chat_api.ask(\n",
    "#         question=test_dataset[\"text\"][0],\n",
    "#     )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
