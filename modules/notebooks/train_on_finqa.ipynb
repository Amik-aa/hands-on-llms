{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 10:35:35,285 - INFO - Initializing resources...\n",
      "2023-08-08 10:35:35,285 - INFO - Loading environment variables from /home/pauliusztin/Documents/projects/hands-on-llms/modules/.env\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "================================================================================\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib64')}\n",
      "DEBUG: Possible options found for libcudart.so: set()\n",
      "CUDA SETUP: PyTorch settings found: CUDA_VERSION=117, Highest Compute Capability: 8.6.\n",
      "CUDA SETUP: To manually override the PyTorch CUDA version please see:https://github.com/TimDettmers/bitsandbytes/blob/main/how_to_use_nonpytorch_cuda.md\n",
      "CUDA SETUP: Loading binary /home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "CUDA SETUP: Problem: The main issue seems to be that the main CUDA runtime library was not detected.\n",
      "CUDA SETUP: Solution 1: To solve the issue the libcudart.so location needs to be added to the LD_LIBRARY_PATH variable\n",
      "CUDA SETUP: Solution 1a): Find the cuda runtime library via: find / -name libcudart.so 2>/dev/null\n",
      "CUDA SETUP: Solution 1b): Once the library is found add it to the LD_LIBRARY_PATH: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:FOUND_PATH_FROM_1a\n",
      "CUDA SETUP: Solution 1c): For a permanent solution add the export from 1b into your .bashrc file, located at ~/.bashrc\n",
      "CUDA SETUP: Solution 2: If no library was found in step 1a) you need to install CUDA.\n",
      "CUDA SETUP: Solution 2a): Download CUDA install script: wget https://github.com/TimDettmers/bitsandbytes/blob/main/cuda_install.sh\n",
      "CUDA SETUP: Solution 2b): Install desired CUDA version to desired location. The syntax is bash cuda_install.sh CUDA_VERSION PATH_TO_INSTALL_INTO.\n",
      "CUDA SETUP: Solution 2b): For example, \"bash cuda_install.sh 113 ~/local/\" will download CUDA 11.3 and install into the folder ~/local\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      "\n",
      "  warn(msg)\n",
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:166: UserWarning: /home/pauliusztin/anaconda3 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatAPI, FinQATrainingAPI\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/modules/notebooks/../training/__init__.py:63\u001b[0m\n\u001b[1;32m     58\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m\"\u001b[39m\u001b[39mCOMET_MODE\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mONLINE\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m     \u001b[39m# Find out more about Comet ML configuration here: https://www.comet.com/docs/v2/integrations/ml-frameworks/huggingface/#configure-comet-for-hugging-face\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[39m# TODO: Find a better way to initialize the logger and env vars before importing the rest of the packages.\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m api, constants, metrics, models\n\u001b[1;32m     65\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mapi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mconstants\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmetrics\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/modules/notebooks/../training/api/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mChatAPI\u001b[39;00m \u001b[39mimport\u001b[39;00m ChatAPI\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mFinQATrainingAPI\u001b[39;00m \u001b[39mimport\u001b[39;00m FinQATrainingAPI\n\u001b[1;32m      4\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mChatAPI\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFinQATrainingAPI\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/projects/hands-on-llms/modules/notebooks/../training/api/ChatAPI.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Tuple\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpeft\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m constants, models\n\u001b[1;32m     10\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/__init__.py:22\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# flake8: noqa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# There's no way to ignore \"F401 '...' imported but unused\" warnings in this\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# module, but to preserve other warnings. So, don't check this module at all.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.4.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     AutoPeftModel,\n\u001b[1;32m     24\u001b[0m     AutoPeftModelForCausalLM,\n\u001b[1;32m     25\u001b[0m     AutoPeftModelForSequenceClassification,\n\u001b[1;32m     26\u001b[0m     AutoPeftModelForSeq2SeqLM,\n\u001b[1;32m     27\u001b[0m     AutoPeftModelForTokenClassification,\n\u001b[1;32m     28\u001b[0m     AutoPeftModelForQuestionAnswering,\n\u001b[1;32m     29\u001b[0m     AutoPeftModelForFeatureExtraction,\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING, PEFT_TYPE_TO_CONFIG_MAPPING, get_peft_config, get_peft_model\n\u001b[1;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     PeftModel,\n\u001b[1;32m     34\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[1;32m     40\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/auto.py:30\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[1;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     AutoModel,\n\u001b[1;32m     23\u001b[0m     AutoModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     AutoModelForTokenClassification,\n\u001b[1;32m     28\u001b[0m )\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmapping\u001b[39;00m \u001b[39mimport\u001b[39;00m MODEL_TYPE_TO_PEFT_MODEL_MAPPING\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     PeftModel,\n\u001b[1;32m     33\u001b[0m     PeftModelForCausalLM,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     PeftModelForTokenClassification,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m PeftConfig\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/mapping.py:20\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m annotations\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Dict\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpeft_model\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     PeftModel,\n\u001b[1;32m     22\u001b[0m     PeftModelForCausalLM,\n\u001b[1;32m     23\u001b[0m     PeftModelForFeatureExtraction,\n\u001b[1;32m     24\u001b[0m     PeftModelForQuestionAnswering,\n\u001b[1;32m     25\u001b[0m     PeftModelForSeq2SeqLM,\n\u001b[1;32m     26\u001b[0m     PeftModelForSequenceClassification,\n\u001b[1;32m     27\u001b[0m     PeftModelForTokenClassification,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtuners\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     AdaLoraConfig,\n\u001b[1;32m     31\u001b[0m     AdaptionPromptConfig,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     PromptTuningConfig,\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m PromptLearningConfig, _prepare_prompt_learning_config\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/peft_model.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Dict, List, Optional, Union\n\u001b[1;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m \u001b[39mimport\u001b[39;00m dispatch_model, infer_auto_device_map\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mimport\u001b[39;00m AlignDevicesHook, add_hook_to_module, remove_hook_from_submodules\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maccelerate\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_balanced_memory\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/accelerate/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m0.21.0\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39maccelerator\u001b[39;00m \u001b[39mimport\u001b[39;00m Accelerator\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbig_modeling\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     cpu_offload,\n\u001b[1;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m skip_first_batches\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/accelerate/accelerator.py:35\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhooks\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhooks\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcheckpointing\u001b[39;00m \u001b[39mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n\u001b[1;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlogging\u001b[39;00m \u001b[39mimport\u001b[39;00m get_logger\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcuda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     is_xpu_available,\n\u001b[1;32m     33\u001b[0m     save,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[39mif\u001b[39;00m is_tpu_available(check_device\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     38\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch_xla\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mxla_model\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mxm\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/accelerate/utils/__init__.py:131\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m is_deepspeed_available():\n\u001b[1;32m    122\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeepspeed\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    123\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    124\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    128\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    129\u001b[0m     )\n\u001b[0;32m--> 131\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbnb\u001b[39;00m \u001b[39mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    132\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfsdp_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n\u001b[1;32m    133\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mlaunch\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m    134\u001b[0m     PrepareForLaunch,\n\u001b[1;32m    135\u001b[0m     _filter_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     prepare_tpu,\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/accelerate/utils/bnb.py:42\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodeling\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     find_tied_parameters,\n\u001b[1;32m     33\u001b[0m     get_balanced_memory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     set_module_tensor_to_device,\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m is_bnb_available():\n\u001b[0;32m---> 42\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcopy\u001b[39;00m \u001b[39mimport\u001b[39;00m deepcopy\n\u001b[1;32m     47\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mautograd\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_functions\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m \u001b[39mimport\u001b[39;00m Tensor, device, dtype, nn\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n\u001b[1;32m     11\u001b[0m T \u001b[39m=\u001b[39m TypeVar(\u001b[39m\"\u001b[39m\u001b[39mT\u001b[39m\u001b[39m\"\u001b[39m, bound\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.nn.Module\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/optim/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbitsandbytes\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcextension\u001b[39;00m \u001b[39mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madagrad\u001b[39;00m \u001b[39mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39madam\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam, Adam8bit, Adam32bit, PagedAdam, PagedAdam8bit, PagedAdam32bit\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/bitsandbytes/cextension.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mgenerate_instructions()\n\u001b[1;32m     19\u001b[0m     CUDASetup\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39mprint_log_stack()\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'''\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[39m    CUDA Setup failed despite GPU being available. Please run the following command to get more information:\u001b[39m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \u001b[39m    python -m bitsandbytes\u001b[39m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m    Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[39m    to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\u001b[39m\n\u001b[1;32m     27\u001b[0m \u001b[39m    and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues\u001b[39m\u001b[39m'''\u001b[39m)\n\u001b[1;32m     28\u001b[0m lib\u001b[39m.\u001b[39mcadam32bit_grad_fp32 \u001b[39m# runs on an error if the library could not be found -> COMPILED_WITH_CUDA=False\u001b[39;00m\n\u001b[1;32m     29\u001b[0m lib\u001b[39m.\u001b[39mget_context\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mc_void_p\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \n        CUDA Setup failed despite GPU being available. Please run the following command to get more information:\n\n        python -m bitsandbytes\n\n        Inspect the output of the command and see if you can locate CUDA libraries. You might need to add them\n        to your LD_LIBRARY_PATH. If you suspect a bug, please take the information from python -m bitsandbytes\n        and open an issue at: https://github.com/TimDettmers/bitsandbytes/issues"
     ]
    }
   ],
   "source": [
    "\n",
    "import comet_ml\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "from training.api import ChatAPI, FinQATrainingAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:12:07,656 - INFO - Loading FinQA datasets from self._root_dataset_dir=PosixPath('../../dataset')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6251/6251 [00:00<00:00, 9389.32 examples/s]\n",
      "Map: 100%|██████████| 1147/1147 [00:00<00:00, 9340.85 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:12:10,946 - INFO - Debug mode enabled. Truncating datasets...\n",
      "2023-08-08 09:12:10,948 - INFO - Loading model using self._model_id='tiiuae/falcon-7b-instruct'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################################################################################\n",
      "GPU 0 memory available: 12032 MiB\n",
      "GPU 1 memory available: 7854 MiB\n",
      "Available RAM: 59.14852523803711 GB\n",
      "####################################################################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)l-00001-of-00002.bin: 100%|██████████| 9.95G/9.95G [02:03<00:00, 80.3MB/s]\n",
      "Downloading (…)l-00002-of-00002.bin: 100%|██████████| 4.48G/4.48G [00:55<00:00, 80.5MB/s]\n",
      "Downloading shards: 100%|██████████| 2/2 [03:00<00:00, 90.05s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.22s/it]\n",
      "Downloading (…)neration_config.json: 100%|██████████| 111/111 [00:00<00:00, 1.16MB/s]\n"
     ]
    }
   ],
   "source": [
    "training_api = FinQATrainingAPI(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 12\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_api._training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:18:53,260 - INFO - Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pauliusztin/.cache/pypoetry/virtualenvs/training-6xkSxa8Q-py3.10/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/iusztinpaul/hands-on-llms/53b88214ae2449faa77d470bcb8362a5\n",
      "\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 01:02, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.169600</td>\n",
       "      <td>2.161291</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>2.158099</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.000800</td>\n",
       "      <td>2.153468</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:19:14,406 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:14,472 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:14,473 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:15,464 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:15,530 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:15,531 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:16,524 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:16,590 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:16,591 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:17,585 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:17,651 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:17,652 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:18,649 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:18,715 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:18,716 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:33,952 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:34,018 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:34,019 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:35,013 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:35,079 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:35,080 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:36,076 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:36,143 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:36,143 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:37,142 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:37,208 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:37,209 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:38,210 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:38,276 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:38,277 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:53,432 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:53,498 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:53,499 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:54,495 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:54,562 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:54,563 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:55,560 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:55,627 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:55,627 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:56,625 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:56,692 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:56,692 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:57,694 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:57,760 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "2023-08-08 09:19:57,761 - INFO - The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/iusztinpaul/hands-on-llms/53b88214ae2449faa77d470bcb8362a5\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     epoch [7]                   : (0.33, 1.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_loss [3]               : (2.153467893600464, 2.1612908840179443)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_perplexity [3]         : (6.771504246216864e-08, 6.859195877950697e-08)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_runtime [3]            : (6.9485, 6.9809)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_samples_per_second [3] : (0.859, 0.863)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     eval_steps_per_second [3]   : (0.859, 0.863)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     learning_rate               : 0.0002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [4]                    : (0.5245167016983032, 2.1696)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     total_flos                  : 245672765816832.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss                  : 2.110236565272013\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_runtime               : 63.7355\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_samples_per_second    : 0.188\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_steps_per_second      : 0.047\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_n_gpu                                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_no_sync_in_gradient_accumulation          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/_setup_devices                             : cuda:0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adafactor                                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta1                                 : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_beta2                                 : 0.999\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/adam_epsilon                               : 1e-08\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/auto_find_batch_size                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16                                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/bf16_full_eval                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/data_seed                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_drop_last                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_num_workers                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/dataloader_pin_memory                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_broadcast_buffers                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_bucket_cap_mb                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_find_unused_parameters                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout                                : 1800\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ddp_timeout_delta                          : 0:30:00\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/debug                                      : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/deepspeed_plugin                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/default_optim                              : adamw_hf\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/device                                     : cuda:0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/disable_tqdm                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/distributed_state                          : Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_eval                                    : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_predict                                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/do_train                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_accumulation_steps                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_batch_size                            : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_delay                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/eval_steps                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/evaluation_strategy                        : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16                                       : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_backend                               : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_full_eval                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fp16_opt_level                             : O1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/framework                                  : pt\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp                                       : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_config                                : {'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_min_num_params                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/fsdp_transformer_layer_cls_to_wrap         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/full_determinism                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_accumulation_steps                : 4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/gradient_checkpointing                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/greater_is_better                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/group_by_length                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/half_precision_backend                     : auto\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_model_id                               : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_private_repo                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_strategy                               : HubStrategy.EVERY_SAVE\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/hub_token                                  : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ignore_data_skip                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/include_inputs_for_metrics                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/jit_mode_eval                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_names                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/label_smoothing_factor                     : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/learning_rate                              : 0.0002\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/length_column_name                         : length\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/load_best_model_at_end                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_process_index                        : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/local_rank                                 : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level                                  : passive\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_level_replica                          : warning\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/log_on_each_node                           : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_dir                                : ../../logs\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_first_step                         : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_nan_inf_filter                     : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_steps                              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/logging_strategy                           : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/lr_scheduler_type                          : SchedulerType.CONSTANT\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_grad_norm                              : 0.3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/max_steps                                  : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/metric_for_best_model                      : loss\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/mp_parameters                              : \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/n_gpu                                      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/no_cuda                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/num_train_epochs                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim                                      : OptimizerNames.PAGED_ADAMW\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/optim_args                                 : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/output_dir                                 : ../../results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/overwrite_output_dir                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/parallel_mode                              : ParallelMode.NOT_PARALLEL\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/past_index                                 : -1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_eval_batch_size                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_device_train_batch_size                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_eval_batch_size                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/per_gpu_train_batch_size                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/place_model_on_device                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/prediction_loss_only                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/process_index                              : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_model_id                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_organization                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/push_to_hub_token                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/ray_scope                                  : last\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/remove_unused_columns                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/report_to                                  : ['comet_ml']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/resume_from_checkpoint                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/run_name                                   : ../../results\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_on_each_node                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_safetensors                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_steps                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_strategy                              : IntervalStrategy.STEPS\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/save_total_limit                           : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/seed                                       : 42\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/sharded_ddp                                : []\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_log                                 : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/should_save                                : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/skip_memory_metrics                        : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tf32                                       : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_backend                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torch_compile_mode                         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/torchdynamo                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_metrics_debug                          : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/tpu_num_cores                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/train_batch_size                           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_ipex                                   : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_legacy_prediction_loop                 : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/use_mps_device                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_ratio                               : 0.03\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/warmup_steps                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/weight_decay                               : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/world_size                                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     args/xpu_backend                                : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_auto_class                              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_commit_hash                             : eb410fb6ffa9028e97adb801f0d6ec46d02f8b07\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/_name_or_path                            : tiiuae/falcon-7b-instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/add_cross_attention                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/alibi                                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/apply_residual_connection_post_layernorm : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/architectures                            : ['RWForCausalLM']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attention_dropout                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/attribute_map                            : {'num_hidden_layers': 'n_layer', 'num_attention_heads': 'n_head'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/auto_map                                 : {'AutoConfig': 'tiiuae/falcon-7b-instruct--configuration_RW.RWConfig', 'AutoModelForCausalLM': 'tiiuae/falcon-7b-instruct--modelling_RW.RWForCausalLM'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bad_words_ids                            : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/begin_suppress_tokens                    : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bias                                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/bos_token_id                             : 11\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/chunk_size_feed_forward                  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/cross_attention_hidden_size              : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/decoder_start_token_id                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/diversity_penalty                        : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/do_sample                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/early_stopping                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/encoder_no_repeat_ngram_size             : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/eos_token_id                             : 11\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/exponential_decay_length_penalty         : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/finetuning_task                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_bos_token_id                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/forced_eos_token_id                      : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/head_dim                                 : 64\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/hidden_dropout                           : 0.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/hidden_size                              : 4544\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/id2label                                 : {0: 'LABEL_0', 1: 'LABEL_1'}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/initializer_range                        : 0.02\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_composition                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_decoder                               : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/is_encoder_decoder                       : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/keys_to_ignore_at_inference              : ['past_key_values']\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/label2id                                 : {'LABEL_0': 0, 'LABEL_1': 1}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/layer_norm_epsilon                       : 1e-05\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/length_penalty                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/max_length                               : 20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/min_length                               : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/model_type                               : RefinedWebModel\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/multi_query                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_head                                   : 71\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/n_layer                                  : 32\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/name_or_path                             : tiiuae/falcon-7b-instruct\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/no_repeat_ngram_size                     : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beam_groups                          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_beams                                : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_labels                               : 2\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/num_return_sequences                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_attentions                        : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_hidden_states                     : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/output_scores                            : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pad_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/parallel_attn                            : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/prefix                                   : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/problem_type                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/pruned_heads                             : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/quantization_config                      : BitsAndBytesConfig {\n",
      "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "  \"bnb_4bit_quant_type\": \"nf4\",\n",
      "  \"bnb_4bit_use_double_quant\": true,\n",
      "  \"load_in_4bit\": true\n",
      "}\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/remove_invalid_values                    : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/repetition_penalty                       : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict                              : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/return_dict_in_generate                  : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/rotary                                   : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/sep_token_id                             : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/suppress_tokens                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/task_specific_params                     : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/temperature                              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tf_legacy_loss                           : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_encoder_decoder                      : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tie_word_embeddings                      : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/tokenizer_class                          : None\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_k                                    : 50\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/top_p                                    : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torch_dtype                              : torch.bfloat16\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/torchscript                              : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/transformers_version                     : 4.27.4\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/typical_p                                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_bfloat16                             : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_cache                                : False\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/use_return_dict                          : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     config/vocab_size                               : 65024\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                    : 33 (656.08 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (369.28 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[36m─────────────────────────────────────────────── \u001b[0m\u001b[1;36mNew Comet feature!\u001b[0m\u001b[36m ───────────────────────────────────────────────\u001b[0m\n",
      "Log your models to better track, deploy, share, and reproduce your work using: 'comet_ml.integration.pytorch.log_model'.\n",
      "Learn more at: https://comet.com/docs/v2/pytorch_log_model\n",
      "\n",
      "Hide this message by setting environment variable \"COMET_DISABLE_ANNOUNCEMENT=1\" \n",
      "\u001b[36m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 6 file(s), remaining 460.23 MB/656.14 MB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-08 09:20:15,934 - INFO - Logging best model from ../../results/checkpoint-3 to the model registry...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/iusztinpaul/hands-on-llms/bcc002e365064a97bbee6d5cf324cba3\n",
      "\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/iusztinpaul/hands-on-llms/bcc002e365064a97bbee6d5cf324cba3\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details      : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed) : 1 (369.28 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages       : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model-element            : 11 (218.69 MB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code              : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Still uploading 2 file(s), remaining 146.84 MB/218.75 MB\n"
     ]
    }
   ],
   "source": [
    "trainer = training_api.train()\n",
    "\n",
    " # When we ran the training in a Jupyter Notebook, we have to manually end the Comet ML experiment.\n",
    "experiment = comet_ml.get_global_experiment()\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 2.1696, 'learning_rate': 0.0002, 'epoch': 0.33, 'step': 1},\n",
       " {'eval_loss': 2.161283254623413,\n",
       "  'eval_perplexity': 6.858097378881212e-08,\n",
       "  'eval_runtime': 6.9463,\n",
       "  'eval_samples_per_second': 0.864,\n",
       "  'eval_steps_per_second': 0.864,\n",
       "  'epoch': 0.33,\n",
       "  'step': 1},\n",
       " {'loss': 2.1604, 'learning_rate': 0.0002, 'epoch': 0.67, 'step': 2},\n",
       " {'eval_loss': 2.1581273078918457,\n",
       "  'eval_perplexity': 6.82205012481063e-08,\n",
       "  'eval_runtime': 6.9761,\n",
       "  'eval_samples_per_second': 0.86,\n",
       "  'eval_steps_per_second': 0.86,\n",
       "  'epoch': 0.67,\n",
       "  'step': 2},\n",
       " {'loss': 2.0008, 'learning_rate': 0.0002, 'epoch': 1.0, 'step': 3},\n",
       " {'eval_loss': 2.1535491943359375,\n",
       "  'eval_perplexity': 6.768559757119874e-08,\n",
       "  'eval_runtime': 6.9658,\n",
       "  'eval_samples_per_second': 0.861,\n",
       "  'eval_steps_per_second': 0.861,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3},\n",
       " {'train_runtime': 63.6673,\n",
       "  'train_samples_per_second': 0.188,\n",
       "  'train_steps_per_second': 0.047,\n",
       "  'total_flos': 245672765816832.0,\n",
       "  'train_loss': 2.110257387161255,\n",
       "  'epoch': 1.0,\n",
       "  'step': 3}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.state.log_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = finqa.FinQADataset(\n",
    "#     data_path=ROOT_DATASET_DIR / \"private_test.json\", scope=constants.Scope.TESTING\n",
    "# ).to_huggingface()\n",
    "# test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_api = ChatAPI(peft_model_id=Path(\"..\") / \"results\" / \"checkpoint-280\", max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     chat_api.ask(\n",
    "#         question=test_dataset[\"text\"][0],\n",
    "#     )\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hands-on-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
